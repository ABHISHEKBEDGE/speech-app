const students = [
  {
    name: 'Rishith Sadashiv T N',
    image: '/images/students/rishith.png',
    email: '221022005@iitdh.ac.in',
    rollNumber: 221022005,
    position: 'MS',
    areasOfInterest: 'Speech Processing, ML, AI',
    thesisTitle: 'Fake Speech Detection',
    description: 'NA',
    scholarLink: 'https://scholar.google.com/citations?user=N3On2UUAAAAJ&hl=en',
    linkedin: 'https://www.linkedin.com/in/rishith-sadashiv-t-n/',
    alumni: 'No',
    alumniPosition: 'NA',
    publications: 'https://drive.google.com/open?id=10vnY_QaLV_qqbYxo54NAM2lGmbuye6pY',
  },
  {
    name: 'Ayush Agarwal',
    image: '/images/students/ayush.png',
    email: '201081001@iitdh.ac.in',
    rollNumber: 201081001,
    position: 'MS',
    areasOfInterest: 'Speech, Privacy, Deep Fake and LLM',
    thesisTitle: 'Speech knowledge based speaker anonymization for privacy preservation',
    description: 'The speech signal is unique for each individual which enables person identification. Nowadays recorded speech signals are easily available either in the cloud or public space. This has increased the risk of using the speech signals for malafide intentions. Hence there is a need for privacy preservation with respect to the speaker identity in the speech signals. The privacy preservation can be either for human listening, machines or both. This work presents explorations made in three directions of speaker anonymization depending upon the target with whom anonymization is required: (1) Speaker anonymization for human listeners, (2) Speaker anonymization for machines and (3) Speaker anonymization for both humans and machines.',
    scholarLink: 'https://scholar.google.co.in/citations?user=MJtJtCkAAAAJ&hl=en',
    linkedin: 'https://www.linkedin.com/in/agarwal20008/',
    alumni: 'Yes',
    alumniPosition: 'Security Researcher at McAfee',
    publications: 'https://drive.google.com/open?id=14wv3MJAAh9hhNnvQBYfoJ6-2RamLjgOZ',
  },
  {
    name: 'Tonmoy Rajkhowa',
    image: '/images/students/tonmoy.png',
    email: '212022001@iitdh.ac.in',
    rollNumber: 212022001,
    position: 'PhD',
    areasOfInterest: 'Spoken Language Translation',
    thesisTitle: 'Direct Speech-to-Text Translation',
    description: 'Direct Speech-to-Text Translation (DS2TT) systems have the potential to reduce error propagation as seen in Cascaded Speech-to-Text Translation (CS2TT) because of its unified architecture. However, these direct systems suffer from the complexities of mapping the source speech with the target text representations along with the scarcity of data available for training. As a result, the cascaded system still outperformed even with the compounding of error from Automatic Speech Recognition (ASR) to the Machine Translation (MT) system. The purpose of this research is to investigate the effect of size and quality of data to bring the performance of DS2TT comparable to its cascaded counterpart. This study analyzed the performances between these systems by augmenting the size and by generating high-quality audios for the Prabhupadavani and MuST-C corpora along with the role of Large Acoustic Models (LAMs) in performance enhancement. Additionally, this study explored methods to document un-orthographic low-resourced tribal languages using DS2TT systems. The addition of high-quality audios and size did reduce the performance gap and the utilization of LAMs was found to be effective in bringing the performance of DS2TT systems comparable to CS2TT. The LAMs also contributed to better quality of text translation for low-resource settings. This work will further explore methods to improve the mapping of speech and text representations along with the application of Large Language Models (LLMs) for enhancing DS2TT performance. Also, new techniques of audio generation using Generative AI (GenAI) will be explored for low-resourced settings.',
    scholarLink: 'https://scholar.google.com/citations?user=NmRkcYkAAAAJ&hl=en',
    linkedin: 'https://www.linkedin.com/in/tonmoy-rajkhowa-27a7a1235/',
    alumni: 'No',
    alumniPosition: 'NA',
    publications: 'https://drive.google.com/open?id=11rCYqFFF7t66ivVsHXFJfmHIA3esW_3n',
  },
  {
    name: 'SOIGATA MUKHERJEE',
    image: '/images/students/soigata.png',
    email: '211022004@iitdh.ac.in',
    rollNumber: 'EE21MS005',
    position: 'MS',
    areasOfInterest: 'Automatic Speech Recognition, Machine Learning, Deep Learning',
    thesisTitle: 'Exploration of non-linear features and end to end systems for under-resources ASR',
    description: 'Automatic Speech Recognition (ASR) system converts a spoken utterance into text. Under-resourced (UR) languages are those which lack enough digital resources for ASR development. Accordingly, there are several challenges for building an ASR system for UR languages that provide performance comparable to that of high-resourced (HR) languages. Due to limited digital resources, it is natural to consider traditional machine learning (ML) frameworks for developing ASR. However, the recent trends in deep learning (DL) provides us with different frameworks which can be used to develop ASR for UR languages. A systematic comparative study is needed among different frameworks to understand the efficacy of each approach. This work explores three frameworks for building ASR for UR languages. The first exploration is Development of UR languages ASR using classical ML approaches, namely, Gaussian mixture model - hidden Markov model (GMM-HMM) and Time delay neural network-hidden Markov model (TDNN) frameworks. This exploration will act as baseline system for comparing with later DL explorations. The second exploration is to use DL as a non-linear feature extractor, in place of hand crafted features like mel frequency coefficients (MFCCs). This exploration will help in understanding the significance of DL for better feature extraction and hence improving the ASR performance. The third framework is to use DL models that are trained using large number of languages, fine tune them and use them as models for UR languages ASR. This thesis will describe the attempts made so far in these three directions.',
    scholarLink: 'https://scholar.google.com/citations?hl=en&user=Vekym2UAAAAJ',
    linkedin: 'https://in.linkedin.com/in/sougata-mukherjee-6776a7219',
    alumni: 'No',
    alumniPosition: 'NA',
    publications: 'https://docs.google.com/spreadsheets/d/1D98Vh7neLZQ5GfsKLX44OEWVP2LyLN5tTA96x8zh3FA/edit?usp=sharing',
  },
  {
    name: 'Kumar Kaustubh',
    image: '/images/students/kaustubh.png',
    email: '221022003@iitdh.ac.in',
    rollNumber: '221022003',
    position: 'MS',
    areasOfInterest: 'Speech Processing and Artificial intelligence',
    thesisTitle: 'NA',
    description: 'NA',
    scholarLink: 'https://scholar.google.com/citations?user=G3PR_j8AAAAJ&hl=en&authuser=2',
    linkedin: 'https://www.linkedin.com/in/kumar-kaustubh-2671561b4?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app',
    alumni: 'No',
    alumniPosition: 'NA',
    publications: 'https://drive.google.com/open?id=10bdOpbefCyZNkPyD7XTmTd71rP4vjsxW',
  },
  {
    name: 'Lalaram Arya',
    image: '/images/students/lalaram.png',
    email: '202021004@iitdh.ac.in',
    rollNumber: '202021004',
    position: 'PhD',
    areasOfInterest: 'Speech to speech translation',
    thesisTitle: 'Direct speech to speech translation',
    description: 'DS2ST',
    scholarLink: 'https://scholar.google.com/citations?user=D9UG6EUAAAAJ&hl=en',
    linkedin: 'https://www.linkedin.com/in/lalaram-arya-73b302144/',
    alumni: 'No',
    alumniPosition: 'NA',
    publications: '',
  },
  {
    name: 'Adithya R Narayan',
    image: '/images/students/adithya.png',
    email: '200020002@iitdh.ac.in',
    rollNumber: '200020002',
    position: 'BTech',
    areasOfInterest: 'Image Classification',
    thesisTitle: 'Image classification',
    description: 'Image classification',
    scholarLink: 'https://scholar.google.com/citations?view_op=new_profile&hl=en',
    linkedin: 'https://www.linkedin.com/in/adithya-r-narayan',
    alumni: 'No',
    alumniPosition: 'NA',
    publications: '',
  },
  {
    name: 'Jagabandhu Mishra',
    image: '/images/students/jagabandhu.png',
    email: '183081002@iitdh.ac.in',
    rollNumber: '183081002',
    position: 'PhD',
    areasOfInterest: 'Speech Signal Processing, Speaker and Language Recognition and Diarization',
    thesisTitle: 'Implicit Systems for Spoken Language Diarization',
    description: 'In a code-switched (CS) scenario, the use of Spoken language diarization (LD) as a pre-possessing system is essential. Further, the use of implicit frameworks is preferable over the explicit framework, as it can be easily adapted to deal with low/zero resource languages. In this direction, the works reported in the literature are very few and mostly follow the explicit framework. Hence, this work initially attempted to derive implicit language representations (ILR) from the speech signal, which can give better language discrimination. The human subjective study suggests that, in contrast to speaker discrimination language discrimination requires a larger neighborhood duration and a priori language knowledge. The same is incorporated through computational frameworks to extract discriminative implicit language representation. Inspired by speaker diarization (SD) literature, a fixed segmentation-based LD framework is initially proposed to perform the LD. Observing the confusion in boundary regions, a change point-based LD framework is proposed to perform the LD task. It is observed that the LD performance is improved by including change point information while segmentation. However, it is observed that the performance is reduced drastically while dealing with practical data due to the small segment duration of the secondary language. A self-supervised implicit language representation extraction framework is proposed to resolve the issue to some extent. The use of self-supervised representation improves the performance to 33.24 Jaccard error rate (JER) from 54.74. Further, the use of LD with change point-based segmentation improves the LD performance to 28.82 JER. After that, an implicit self-supervised end-to-end (E2E) LD framework is proposed to further improve the LD performance. The proposed approach improved the LD performance to 21.8 JER.',
    scholarLink: 'https://scholar.google.com/citations?user=l_lY9NQAAAAJ&hl=en',
    linkedin: 'https://in.linkedin.com/in/jagabandhu-mishra-6a83a3ba',
    alumni: 'Yes',
    alumniPosition: 'Post Doctorate Researcher, University of Eastern Finland',
    publications: 'https://drive.google.com/open?id=1qBew3k_wXxaKVjyX_Q5WaYDH7mYZvmPi',
  },
];
  
export default students;